{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3C-gXIFmSj_"
   },
   "outputs": [],
   "source": [
    "#Face Recognition using pre trained Facenet Model and then evaluating using L2 distance\n",
    "Parth Mehta 101903297 CO12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6OrP1C7mRYt"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2EVy_V91hVU6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "--MYWMhjhk6F"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "\n",
    "json_file = open('/content/keras-facenet-h5/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights('/content/keras-facenet-h5/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tSSLp3jYiPH5",
    "outputId": "d4211703-438d-422c-9f91-639bc58fef93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 160, 160, 3) dtype=float32 (created by layer 'input_1')>]\n",
      "[<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'Bottleneck_BatchNorm')>]\n"
     ]
    }
   ],
   "source": [
    "print(model.inputs)\n",
    "print(model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XUQp3nF1iVmY"
   },
   "outputs": [],
   "source": [
    "FRmodel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0jYHxxUYiY7V"
   },
   "outputs": [],
   "source": [
    "def img_to_encoding(image_path, model):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(160, 160))\n",
    "    img = np.around(np.array(img) / 255.0, decimals=12)\n",
    "    x_train = np.expand_dims(img, axis=0)\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding / np.linalg.norm(embedding, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9lBUomk9icVH"
   },
   "outputs": [],
   "source": [
    "database = {}\n",
    "\n",
    "database[\"danielle\"] = img_to_encoding(\"/content/images/danielle.png\", FRmodel)\n",
    "database[\"younes\"] = img_to_encoding(\"/content/images/younes.jpg\", FRmodel)\n",
    "database[\"tian\"] = img_to_encoding(\"/content/images/tian.jpg\", FRmodel)\n",
    "database[\"andrew\"] = img_to_encoding(\"/content/images/andrew.jpg\", FRmodel)\n",
    "database[\"kian\"] = img_to_encoding(\"/content/images/kian.jpg\", FRmodel)\n",
    "database[\"dan\"] = img_to_encoding(\"/content/images/dan.jpg\", FRmodel)\n",
    "database[\"sebastiano\"] = img_to_encoding(\"/content/images/sebastiano.jpg\", FRmodel)\n",
    "database[\"bertrand\"] = img_to_encoding(\"/content/images/bertrand.jpg\", FRmodel)\n",
    "database[\"kevin\"] = img_to_encoding(\"/content/images/kevin.jpg\", FRmodel)\n",
    "database[\"felix\"] = img_to_encoding(\"/content/images/felix.jpg\", FRmodel)\n",
    "database[\"benoit\"] = img_to_encoding(\"/content/images/benoit.jpg\", FRmodel)\n",
    "database[\"arnaud\"] = img_to_encoding(\"/content/images/arnaud.jpg\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_86_6mf1jAsI"
   },
   "outputs": [],
   "source": [
    "def who_is_it(image_path, database, model):\n",
    "\n",
    "\n",
    "    ## Step 1: Compute the target \"encoding\" for the image. Use img_to_encoding() see example above. ## (≈ 1 line)\n",
    "    encoding =  img_to_encoding(image_path,model)\n",
    "    \n",
    "    ## Step 2: Find the closest encoding ##\n",
    "    \n",
    "    # Initialize \"min_dist\" to a large value, say 100 (≈1 line)\n",
    "    min_dist = 100\n",
    "    \n",
    "    # Loop over the database dictionary's names and encodings.\n",
    "    for (name, db_enc) in database.items():\n",
    "        \n",
    "        # Compute L2 distance between the target \"encoding\" and the current db_enc from the database. (≈ 1 line)\n",
    "        dist = np.linalg.norm(encoding-database[name])\n",
    "\n",
    "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines)\n",
    "        if dist<min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "    \n",
    "    \n",
    "    if min_dist > 0.7:\n",
    "        print(\"Not in the database.\")\n",
    "    else:\n",
    "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "        \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lyR8uv6TjO_f",
    "outputId": "e8bbccb0-924b-4cae-9c4d-44db29f09e7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's younes, the distance is 0.59929454\n"
     ]
    }
   ],
   "source": [
    "# Test 1 with Younes's picture \n",
    "test1 = who_is_it(\"/content/images/camera_0.jpg\", database, FRmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98EfvegOjVv4",
    "outputId": "a71abd45-085e-47d4-a4f5-ad115566006d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's bertrand, the distance is 0.5436483\n"
     ]
    }
   ],
   "source": [
    "# Test 2 with Bertrand's picture \n",
    "test2 = who_is_it(\"/content/images/camera_1.jpg\", database, FRmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GcUBAxMnjPuT",
    "outputId": "ae75d20c-0326-4b2c-f9c1-fcba19a6ed9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's younes, the distance is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Test 3 with Younes's picture\n",
    "test3 = who_is_it(\"/content/images/younes.jpg\", database, FRmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A8xfN4-_jpO7",
    "outputId": "d88f6a1d-7032-40c1-ca61-36661b1934b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's benoit, the distance is 0.2783232\n"
     ]
    }
   ],
   "source": [
    "#Test 4 with Benoit's picture\n",
    "test4 = who_is_it(\"/content/images/camera_2.jpg\", database, FRmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ETCMN_ol9VS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ParthMehta-101903297-CO12.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
